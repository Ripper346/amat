\documentclass[10pt,twocolumn,letterpaper]{article}

\include{formatAndDefs}

% \iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}
\title{AMAT: Computing the Medial Axis Tranform for Natural Images Using a Weighted Geometric Set Cover Approach}
\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
The medial axis transform (MAT) is a powerful shape abstraction that has been successfully
used in shape summarization, matching and retrieval. Despite the MAT's
long history, the lack of an adequate definition and evaluation criterion that can accommodate
color and texture have prevented its widespread use for tasks involving natural images.
In this paper we propose a new formulation of the
MAT for natural images as a weighted geometric set cover (WGSC) problem, and we use a greedy 
approximation algorithm to solve it.
Our method, called Appearance-MAT (AMAT), makes the following contributions: 
i) it extends previous methods which were limited to detecting medial axes locations 
in natural images, by associating  each medial point with a local scale; 
ii) inspired by the invertibility property of the 
original MAT for binary images, it also associates each medial point with a local encoding
which allows us to invert the AMAT, faithfully reconstructing the input image; 
iii) this additional information allows us to group individual points into medial branches,
which correspond to meaningful image regions, supporting both image segmentation and boundary
ownership assignment.

We perform experiments in medial point detection on a new dataset of medial axes, called
Berkeley-Medial AXes (BMAX500) based on the popular BSDS500 dataset. 
We also measure the quality of the reconstructed images from the same dataset,
obtained by inverting their computed AMAT. 
Finally, we show that edge maps extracted as a by-product of our method
can be integrated in popular object proposal pipelines, thereby boosting performance.
Our code will be made publicly available.



\stavros{sell more the graph approach?}
\stavros{Say that we don't use learning}
\stavros{Cite: Medial Spheres for Shape Approximation
Svetlana Stolpner, Paul Kry and Kaleem Siddiqi}
\end{abstract}

%%%%%%%%% BODY TEXT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ==========================================================
\section{Introduction}\label{sec:introduction}
% ==========================================================
\begin{itemize}
\item MAT, perceptual grouping, symmetry.
\item application in which MAT has been used (shape matching, shape retrieval etc)
\end{itemize}

\begin{figure}[!t]
\caption{Teaser figure showing example of binary MAT and our extension to color images.
If there is enough space we can show example of image reconstruction and other potential applications.}
\label{fig:teaser}
\end{figure}

% ==========================================================
\section{Related Work}\label{sec:related}
% ==========================================================
\subsubsection*{MAT for binary shapes}
\begin{itemize}
\item Blum's Medial axis transform
\item Other works on extracting skeletons for 2D and 3D shapes (shock graphs,bone graphs,scale axis transform,check out other graphics works)
\end{itemize}
\subsubsection*{MAT for natural images}
\begin{itemize}
\item Levinstein's work
\item MIL-based symmetry detection
\item Random-forest variant by Alloimonos' student
\item CNN-variant 
\end{itemize}

% ==========================================================
\section{Background}\label{sec:background}
% ==========================================================
\stavros{Probably move this section to~\refsec{sec:method}}
To make the paper self-contained, we include a brief review of two basic concepts that our work is based on.

\subsubsection*{Medial Axis Transform}
Consider a two-dimensional binary shape, $O$, in the image plane, and its boundary $\Theta_O$.
The \emph{medial axis} of $O$ is the set of points $\vec{p}$ that lie midway between two sections of 
its boundary. The points $\vec{p}$ are the centers of maximally inscribed (medial) disks, bitangent to $\Theta_O$
in the interior of the shape. The radius $r(\vec{p})$ of the disk is the distance between $\vec{p}$ and 
the points where the disk touches $\Theta_O$, and is called the \emph{medial radius}.
Based on the above definitions, the \emph{medial axis transform} is the process of 
mapping $O$ to the set of tuples $(\vec{p},r(\vec{p})) \in \mathbb{R}^2 \times \mathbb{R}$.
Given these pairs, we can reconstruct the object as a union of overlapping disks that sweep-out 
its interior. 

\subsubsection*{Weighted Geometric Set Cover}
The geometric set cover is the extension of the well studied set cover problem, in a geometric space.
For simplicity, here we only consider the case of a two-dimensional space and we particularly focus in the 
\emph{weighted} version of the problem, which is defined as follows:
Consider a universe of $n$ points $\set{X} \in \R^2$ and a family of sets 
$\set{D} = \{D_1,D_2,\ldots,D_m\} \subseteq \set{X}$. 
A common choice for these sets are intersections of $\set{X}$ with simple shape primitives, such as disks or rectangles.

Now assume that each set in $\set{D}$ is associated with a non-negative weight or \emph{cost} $c_i$.
Solving the WGSC problem amounts to finding a sub-collection $\bar{\set{D}} \in \set{D}$ that covers the entire $\set{X}$
(all $n$ elements of $\set{X}$ are contained in at least one set in $\bar{\set{D}}$), while having the minimum
total cost $C$; the total cost is simply the sum of costs of individual elements in $\bar{\set{D}}$.

WGSC is a strongly NP-hard problem for which polynomial-time approximate solutions (PTAS) exist.
Perhaps the simplest and most straightforward is the greedy algorithm described in~\cite{vazirani2013approximation}. 
\stavros{We will include pseudocode for the algorithm applied in our own problem}
The interested reader can find more details on WGSC and related algorithms in~\cite{mustafa2015quasi,varadarajan2010weighted,har2012weighted,chan2012weighted}.


% ==========================================================
\section{Method}\label{sec:method}
% ==========================================================
\subsection{Problem Definition}\label{sec:definition}
Our definition of a medial axis transform for color images is inspired by the invertibility property of the binary MAT. 
Given a medial point $\p{i}$ and its associated scale $r_i$, we can reconstruct part of the shape by 
``expanding'' a value of one (1) inside the area covered by the medial disk or radius $r_i$, centered at $\p{i}$.
Repeating this process for all points lying on the medial axis, results in a reconstruction of the full shape.

We argue that a MAT for real images should satisfy a similar principle: given the MAT of an image, 
we should be able to ``invert'' it, reconstructing \emph{the image} itself.
There are several reasons why extending this idea from binary to real images is a challenging task. 
Natural images contain complex scenes and are cluttered with various objects, instead of a single foreground shape. 
Moreover, whereas binary images are composed of uniform areas of zeros (0) and ones (1), 
real images obey complicated color and texture distributions. 
Nevertheless, we can assume that in most cases an image is composed of many small regions of relatively uniform appearance. 
This is a concept on which most superpixel algorithms are built on: group pixels 
into non-overlapping patches that capture image redundancies, while respecting perceptually meaningful region boundaries~\cite{shi2000normalized,levinshtein2009turbopixels,achanta2012slic}. 

\stavros{boldface encodings and decodings}
\paragraph{Notation:} Before proceeding with the details of our formulation, we list the notation used throughout our paper.
We use capital italics for single elements and capital calligraphic letters to denote sets. A disk of radius $r$,
centered at point $\p{}$ is denoted as $D(\p{},r)=D_{\p{},r}$. 
For brevity, we ofter refer to such a disk as a $r$-disk or $(\p{},r)$-disk.
We will also occasionally use $r(\p{}) = r_{\p{}}$ to refer to the radius/scale $r$, associated with point $\p{}$.
$\set{D}$ is a collection of such disks of varying centers and radii, $\set{D}=\{ D_{\p{i},r_{\p{i}}} \},\, i\in\mathbb{N}$.
The interesection of a $(\p{},r)$-disk with and image $I$ is a disk-shaped region of the image, and is denoted by 
$I \cap D_{\p{},r}=D_{\p{},r}^I \subset I$. Finally, we use $\circ$ to denote function composition.

\paragraph{Formulation:} Consider an RGB image $I\subset\R^2$, and a disk-shaped region $D_{\p{},r}^I \subset I$.
Let $f:\R^2 \rightarrow \R^K$ be a function that maps $D_{\p{},r}^I$ to a vector representation $f_{\p{},r}=f\circ D_{\p{},r}^I$. 
We call this representation the \emph{encoding} of $D_{\p{},r}^I$. 
Now let $g:\R^K \rightarrow \R^2$ be a function that maps this encoding back to a disk patch $\tilde{D}_{\p{},r}^I$: 
$g_{\p{},r} = g \circ f_{\p{},r} = \tilde{D}_{\p{},r}^I$. We call $g$ the \emph{decoding} function.
In the general case, $f$ and $g$ will be \emph{lossy} mappings, which means that the reconstruction error 
$e_{\p{},r} = \norm{ \tilde{D}_{\p{},r}^I - D_{\p{},r}^I}_2 \geq 0$. 

Using the above notions, we define the MAT as the set of tuples 
$M:\{ ( \p{1},r_{\p{1}}, f_{\p{1},r_{\p{1}}}, \ldots, ( \p{m},r_{\p{m}}, f_{\p{m},r_{\p{m}}} ) \}$, such that:
\begin{equation}
M = \argmin_{\p{},r}{\sum_{i=1}^m e_{\p{i},r_i}},\quad I=\bigcup_{i=1}^m D_{\p{i},r_i}^I 
\label{eq:minimization}
\end{equation}
Although $f,g$ can be any arbitrary functions, in this paper we opt for simplicity:
$f$ computes the mean of each color channel ``summarizing'' $D_{\p{},r}^I$, in a $3\times1$ vector $f_{\p{},r}$.
Conversely, $g$ constructs an approximation $\tilde{D}_{\p{},r}^I \approx D_{\p{},r}^I$ by replicating $f_{\p{},r}$ in the
respective disk-shaped area.
When the $(\p{},r)$-disk is fully enclosed in a region with uniform color, the reconstruction error $e_{\p{},r}$
is low, whereas when the disk crosses a strong image boundary, the encoding $f_{\p{},r}$ cannot accurately represent
the underlying image region, resulting in a higher error. Since each point is associated not only with position and local
scale information, but also with local appearance information (in the form of a color triplet), we dub our approach
\emph{Appearance}-MAT or \emph{AMAT}. \stavros{Should we change that with Color-MAT (CMAT)?}

Note that the definition in~\refeq{eq:minimization} suggests conceptual similarities with superpixel representations.
Selecting the set of tuples $\{(\p{i},r_i,f_{\p{i},r_i})\},\,i=1,\ldots,m$ is equivalent to covering the input image
with $m$ disk-shaped superpixels. Minimizing the total reconstruction error implies that these ``superdisks'' do not
cross region boundaries, as this would incur a high reconstruction error, as shown in~\reffig{fig:google}.
However, there are two main differences with respect to traditional superpixels.
First, in our method we use a canonical
superpixel shape (disks), whereas superpixels can generally assume any shape. Second, selecting points $(\p{i},r_i)$
so as to minimize~\refeq{eq:minimization} can result in \emph{overlapping} disks, which is in contrast to standard superpixels
which are non-overlapping. 

\begin{figure}[ht]
\caption{Image of google logo, showing how we use disks to cover the input image, and how disks that cross region boundaries result
in high reconstruction costs.}
\label{fig:google}
\end{figure}


\subsection{AMAT as a Geometric Set Cover Problem}\label{sec:amat-wgsc}
We now show how our formulation of the medial axis transform described in~\refsec{sec:method} lends itself naturally to a 
weighted geometric set cover (WGSC) interpretation.
The input image $I\subset\R^2$ is our universe of $N$ points.
For practical reasons, we only consider $r$-disks with $r$ chosen from a finite set of radii $r\in\set{R}:\{r_1,r_2,\ldots,r_R\}$.
The $r$-disks, $r\in\set{R}$ can be placed at any position $\p{}=(x,y)\in I$ such that $D_{\p{},r}$ is fully contained in $I$.
We also assign a cost $c_{\p{i},r_j} = c_{ij}$ to each possible $(\p{i},r_j)$-disk, $i\in[1,N],\, j\in[1,R]$.
This cost is directly related to the reconstruction cost 
$e_{\p{i},r_j}=\norm{D_{\p{i},r_i}^I - \tilde{D}_{\p{i},r_j}^I} = e_{ij}$, given the functions $f,g$.
Note that for brevity, we drop the subscripts $\p{i},r_j$ and simply use $ij$ to refer to a $(\p{i},r_j)$-disk.
We will provide more details regarding computation of $e_{ij}$ in~\refsec{sec:implementation}.
For now, we focus on making the connection of our problem to the WGSC and show how we can solve it.

As~\refeq{eq:minimization} suggests, the goal is to find a subset of disks that cover the entire image, while maintaining
a low total reconstruction cost. 
A trivial solution would be to select each pixel as a disk of radius $r=1$, in which case
$M:\{ (\p{1},r_{\p{1}},f_{\p{1},r_{\p{1}}}), \ldots, ( \p{N},r_{\p{N}},f_{\p{N},r_{\p{N}}} ) \}$,
and $\sum_{i=1}^N e_{\p{i},r_i} = 0$; each pixel can be perfectly represented by its mean value.
Such a solution is of no practical usefulness. 
In accordance with the spirit of the medial axis transform, we seek a solution that is \emph{sparse}
(low number of medial points $m$), while being able to adequately reconstruct the input image.
In the original MAT, sparsity is implicitly is induced through the disk maximality criterion:
a point belongs to the medial axis if it is the center of the largest disk that touches 
the shape boundary at exactly two points, thus ensuring that the disk remains completely in the 
interior of the shape.

Extending the maximality principle to the case of natural images is not straightforward.
Contrary to the case of binary shapes, the notion of the boundary in real images is not strictly defined.
Furthermore, relying on the output of a boundary extraction algorithm would make our method very sensitive
to boundary detection errors, from which it would be difficult to recover.
For these reasons we choose to regularize the minimization criterion in~\refeq{eq:minimization} in a alternative way. 
We add a scale-dependent cost term $s_j = \frac{w_s}{r_j}$ to the costs $c_{ij}$, with $s_j$ 
being inversely proportional to the radius $r_j$.
In this way, we favor the selection of larger disks at each point, as long as $s_j$ is not ``too'' large
with respect to the error incurred by picking $D_{\p{},r_{j+1}}$ instead of $D_{\p{},r_j}$.
Selecting a high value for $w_s$ will lead to a sparser solution with higher total reconstruction error $E$,
whereas a low value for $w_s$ will aim for a higher reconstruction quality, by utilizing more, smaller disks
to cover $I$.

\paragraph{Greedy approximation algorithm}
There are many choices for a polynomial-time-approximate-solution (PTAS) algorithms for the vanilla set cover
and its geometric variants.
Some rely on solving the dual \emph{hitting set problem}~\cite{bronnimann1995almost}.
\stavros{review papers and add more details about previous work on that.}

Since this is a first attempt on applying a WGSC approach to compute the MAT of real images, we keep things simple.
We use the greedy approximation algorithm for the set cover, described in~\cite{vazirani2013approximation},
adapted for the weighted case.
The steps of our method are described in Algorithm~\ref{alg:greedy}
\begin{algorithm}
\caption{AMAT greedy algorithm.}
\label{alg:greedy}
	\begin{algorithmic}[1]
	\Statex \textbf{Input:} $X,I=\{\p{1},\ldots,\p{N}\},\set{R}=\{r_1,\ldots,r_R\},f,g$.
	\Statex \textbf{Output:} $M$
	\State Initialization: $M = \emptyset,X=\emptyset$.
	\State Compute $f_{\p{},r},\, g_{\p{},r} = g \circ f_{\p{},r},\,\, \forall \p{} \in I, \forall r \in \set{R}$.
	\While{$X \subset I$}
		\State $c_{\p{},r}^e = \frac{c_{\p{},r}}{|D_{\p{},r} \setminus X|}+\frac{w_s}{r},\,\, \forall \p{} \in I, \forall r \in \set{R}$.		
		\State $M\leftarrow M\cup{(\p{}^{*},r^{*},f_{\p{}^{*},r^{*}})},  \newline
				X \leftarrow X\cup D_{\p{}^{*},r^{*}}, \quad (\p{}^{*},r^{*}) = \argmin_{\p{},r}{c_{\p{},r}^e}$.		
	\EndWhile
	\end{algorithmic}
\end{algorithm}
We start by computing the costs $c_{ij}$ for all possible disks $D_{ij}$.
We define the \emph{effective cost} of $D_{ij}$ as $c_{ij}^e = \frac{c_{ij}}{A_{ij}} + s_j$ , where $A_{ij}$ is the number
of \emph{new} pixels covered by $D_{ij}$ (pixels that have not been covered by a previously selected disk).
Starting from an empty set $M$, we pick the disk with the lowest $c_{ij}^e$ and add it to the solution, 
removing the area $D_{ij}$ from the pixels that have to be covered.
This process is repeated until all image pixels have been covered by at least one disk.

 
\subsection{Implementation Details}\label{sec:implementation}
In this section we discuss implementation details of our approach, as well as design and parameter choices.
\stavros{Perhaps add subsubsection about the choice of encoding and decoding functions}
\subsubsection*{Choice of functions encoding and decoding functions}
\subsubsection*{Heuristic disk cost}
The greedy algorithm described in~\refsec{sec:amat-wgsc} requires assigning a cost to all possible disks $D_{ij}$.
Choosing an appropriate type of cost function is crucial towards obtaining a final MAT that both encompasses the 
disk maximality criterion, leading to a sparse solution, and faithfully reproduces the input image.
Since our objective is a high quality of image reconstruction, $c_{ij}$ should be directly proportional
to the reconstruction error of the local image patch.
Given our choice of functions $f,g$, using a criterion such as MSE or PSNR will not work.
These metrics are well known to perform poorly in representing perceptual similarity of images~\cite{girod1993what,wang2009mean}.
For example, \reffig{fig:heuristic} shows that naively selecting a disk with a low MSE score does not guarantee that it 
does not cross image boundaries.
Instead, we would rather select disks whose encodings are representative of \emph{all} disks that are fully enclosed
in their area. 
First, we convert the RGB input image to the CIELAB color space which is more suitable for measuring perceptual distances,
and perform all our computations in that space.
We define the cost for a disk $D_{\p{i},r_j}$ as follows:
\begin{equation}
c_{ij} = \sum_k \sum_l \norm{\mathbf{f}_{ij} - \mathbf{f}_{kl} }^2, \forall k,l: D_{kl} \subset D_{ij}
\label{eq:diskcost}
\end{equation}
Intuitively, a low cost $c_{ij}$ implies that the encoding $\mathbf{f}_{ij}$ is representative of \emph{all}
the disks that are fully contained in $D_{ij}$, hence $D_{ij}$ is not crossing any region boundaries.

Computing $c_{ij}$ can be very demanding as it requires to also compute mean value encodings for all


\begin{figure}
\caption{Figure showing the intuition behind our heuristic for disk error computation, and the failure of MSE}
\label{fig:heuristic}
\end{figure}


\subsubsection*{Dealing with textured images}
\subsubsection*{Reconstructing the image from AMAT}
\subsubsection*{Parameter values}

\subsection{Grouping Medial Points to Branches}\label{sec:grouping}

% ==========================================================
\section{Experiments}\label{sec:experiments}
% ==========================================================
\subsection{Image Reconstruction (BSDS500)}
Experiments on image reconstruction using standard metrics (MSE, PSNR, and metrics using CNN feature similarity.

\subsection{Medial Point Detection (BMAX500)}\label{sec:medial-point-detection}
Recover all medial axes of the BSDS500. Compare with other skeletonization algorithms, such
as the CNN based method, and my previous MIL-based method

\subsection{Boundary Detection (BSDS500)}\label{sec:boundary-detection}
Medial axes to boundaries. 
MIL: compute an approximate scale based on the scale with maximum probability and try to recover boundaries.
CNN: same as above, this was already done in that paper for estimating segmentation masks using scale information.
We can compare the boundary recovery results as well.
EDGE DETECTORS: Standard edge detection algorithms (Dollar, HED, Canny, gPB etc: compare with algorithms specifically
tailored for this task. WE ARE NOT EXPECTING SOTA PERFORMANCE.

\subsection{Object Proposals}\label{sec:object-proposals}


% ==========================================================
\section{Discussion}\label{sec:discussion}
% ==========================================================

{\small
\bibliographystyle{ieee}
\bibliography{iccv2017}
}

\end{document}
